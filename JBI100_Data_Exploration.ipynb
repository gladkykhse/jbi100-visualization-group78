{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JBI100 Visualization \n",
    "### Academic year 2024-2025\n",
    "\n",
    "## Incidents and Accidents\n",
    "Data sources:\n",
    "\n",
    "- Work-related Injury and Illness (https://www.osha.gov/Establishment-Specific-Injury-and-Illness-Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Do not truncate tables\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 – Data Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) What is the information you can obtain from the data set/ data sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OSHA Injury Tracking Application (ITA) Case Detail dataset contains detailed information on work-related injuries and illnesses (each row is a case of work-related injuries or illnesses). The data includes the following types of information:\n",
    "\n",
    "#### 1. Establishment-Level Information\n",
    "- **Unique Identifiers**: Establishment ID, Employer Identification Number (EIN).\n",
    "- **Demographic Information**: Establishment name, company name, street address, city, state, zip code.\n",
    "- **Industry Classification**: North American Industry Classification System (NAICS) code, year of NAICS code used, industry description.\n",
    "- **Establishment Type**: Private industry, state government entity, or local government entity.\n",
    "- **Workforce Data**: Size of the establishment, annual average employees, total hours worked.\n",
    "\n",
    "#### 2. Incident-Level Information\n",
    "- **Incident Identifiers**: Unique case number, establishment ID linkable to 300A data.\n",
    "- **Incident Details**: Date of incident, type of incident (injury, skin disorder, etc.), time of incident, time started work prior to incident, and whether time was unknown.\n",
    "- **Outcomes**: Most serious outcome (e.g., death, days away from work, job transfer/restriction), number of days away from work, number of restricted duty or transfer days.\n",
    "- **Fatalities**: Date of death (if applicable).\n",
    "\n",
    "#### 3. Narrative Descriptions\n",
    "- **Incident Details**: What the employee was doing before the incident, how the incident happened, injury/illness description, and the object/substance directly harming the employee.\n",
    "\n",
    "#### 4. Occupational Coding Information\n",
    "- **Job Information**: Job title of the injured/ill employee.\n",
    "- **Standard Occupation Code (SOC)**:\n",
    "  - SOC Code and Description: Assigned using NIOCCS.\n",
    "  - SOC Probability: Confidence score for SOC coding.\n",
    "  - SOC Reviewed: Indicates whether the SOC code was reviewed or reassigned.\n",
    "\n",
    "#### 5. System Metadata\n",
    "- **Submission Information**: Created timestamp, year of filing.\n",
    "- **Data Quality Indicators**: Codes for missing or invalid entries (e.g., \"9999\" for SOC code when unassignable).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) What are the attributes in the data and what is their meaning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OSHA Injury Tracking Application (ITA) Case Detail dataset includes the following attributes, categorized by their context and meaning:\n",
    "\n",
    "#### 1. **Establishment Information**\n",
    "- **`establishment_ID`**: Unique identifier for each establishment.\n",
    "- **`establishment_name`**: Name of the establishment reporting the data.\n",
    "- **`ein`**: Employer Identification Number (Federal Tax Identification Number).\n",
    "- **`company_name`**: Name of the parent company of the establishment.\n",
    "- **`street_address`**: Street address of the establishment.\n",
    "- **`city`**: City where the establishment is located.\n",
    "- **`state`**: State or territory where the establishment is located.\n",
    "- **`zip_code`**: Full zip code of the establishment.\n",
    "- **`naics_code`**: North American Industry Classification System (NAICS) code for the establishment.\n",
    "- **`naics_year`**: Year version of NAICS code used.\n",
    "- **`industry_description`**: Industry description based on the NAICS code.\n",
    "- **`establishment_type`**: Type of establishment:\n",
    "  - 1 = Private industry\n",
    "  - 2 = State government entity\n",
    "  - 3 = Local government entity\n",
    "- **`size`**: Size of the establishment based on maximum employees:\n",
    "  - 1 = <20 employees\n",
    "  - 21 = 20-99 employees\n",
    "  - 22 = 100-249 employees\n",
    "  - 3 = 250+ employees\n",
    "- **`annual_average_employees`**: Annual average number of employees.\n",
    "- **`total_hours_worked`**: Total hours worked by all employees at the establishment.\n",
    "\n",
    "#### 2. **Incident Information**\n",
    "- **`case_number`**: Employer-assigned unique case number for each injury/illness.\n",
    "- **`date_of_incident`**: Date when the incident occurred.\n",
    "- **`incident_outcome`**: Most serious outcome of the incident:\n",
    "  - 1 = Death\n",
    "  - 2 = Days away from work (DAFW)\n",
    "  - 3 = Job transfer or restriction\n",
    "  - 4 = Other recordable case\n",
    "- **`dawf_num_away`**: Number of days away from work due to the incident.\n",
    "- **`djtr_num_tr`**: Number of days on restricted duty or job transfer due to the incident.\n",
    "- **`type_of_incident`**: Type of incident:\n",
    "  - 1 = Injury\n",
    "  - 2 = Skin disorder\n",
    "  - 3 = Respiratory condition\n",
    "  - 4 = Poisoning\n",
    "  - 5 = Hearing loss\n",
    "  - 6 = All other illness\n",
    "- **`time_started_work`**: Time the employee began work prior to the incident.\n",
    "- **`time_of_incident`**: Time the incident occurred.\n",
    "- **`time_unknown`**: Indicator if the time of the incident is unknown:\n",
    "  - 0 = No\n",
    "  - 1 = Yes\n",
    "- **`date_of_death`**: Date of death, if applicable.\n",
    "\n",
    "#### 3. **Narrative Descriptions**\n",
    "- **`incident_description`**: Description of the incident.\n",
    "- **`nar_before_incident`**: Description of what the employee was doing before the incident.\n",
    "- **`nar_what_happened`**: Description of what happened during the incident.\n",
    "- **`nar_injury_illness`**: Description of the injury or illness.\n",
    "- **`nar_object_substance`**: Description of the object or substance directly harming the employee.\n",
    "\n",
    "#### 4. **Occupational Information**\n",
    "- **`job_description`**: Job title of the injured/ill employee.\n",
    "- **`SOC_code`**: Standard Occupation Code assigned by NIOCCS or OSHA.\n",
    "- **`SOC_description`**: Text description of the SOC code.\n",
    "- **`SOC_probability`**: Confidence score for the SOC coding (5 indicates a manually reassigned code).\n",
    "- **`SOC_reviewed`**: Indicator of whether the SOC code was reviewed:\n",
    "  - 0 = Not reviewed, NIOCCS coded\n",
    "  - 1 = Reviewed by OSHA\n",
    "  - 2 = Not SOC coded (SOC = \"9999\")\n",
    "\n",
    "#### 5. **System Metadata**\n",
    "- **`created_timestamp`**: Timestamp when the record was submitted.\n",
    "- **`year_of_filing`**: Year in which the reported injuries/illnesses occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Write a small parsing function that can read the data position (column, row) from the file format you selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset():\n",
    "    dataset_path = os.path.join(\n",
    "        \"Work-related Injury and Illness\",\n",
    "        \"ITA Case Detail Data 2023 through 8-31-2023.csv\",\n",
    "    )\n",
    "    return pd.read_csv(\n",
    "        dataset_path,\n",
    "        delimiter=\",\",\n",
    "        low_memory=False,\n",
    "        encoding=\"utf-8\",\n",
    "        dtype={\"zip_code\": \"string\", \"naics_code\": \"string\", \"naics_year\": \"string\"},\n",
    "        index_col=\"id\",\n",
    "    )\n",
    "\n",
    "\n",
    "df = parse_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Write another function that outputs the distribution of the attributes, and counts the frequencies of the different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_distribution(df):\n",
    "    \"\"\"\n",
    "    Creates a DataFrame where:\n",
    "    - Primary index: column names (attributes)\n",
    "    - Secondary index: unique values in each column\n",
    "    - Value column: frequency of each unique value\n",
    "\n",
    "    Parameters:\n",
    "    - df (pd.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Frequency distribution as described.\n",
    "    \"\"\"\n",
    "    frequency_df = pd.concat(\n",
    "        {col: df[col].value_counts() for col in df.columns},\n",
    "        names=[\"Attribute\", \"Value\"],\n",
    "    ).reset_index(name=\"Frequency\")\n",
    "\n",
    "    # Set the index as required\n",
    "    return frequency_df.set_index([\"Attribute\", \"Value\"])\n",
    "\n",
    "\n",
    "df_frequency = get_frequency_distribution(df)\n",
    "df_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_distribution(dataframe, attribute, plot_distribution=False):\n",
    "    \"\"\"\n",
    "    Calculates the distribution of values for a specified attribute in the dataset\n",
    "    and optionally plots the distribution using Plotly Express.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The DataFrame containing the dataset.\n",
    "        attribute (str): Column name of the attribute to analyze.\n",
    "        plot_distribution (bool): Whether to plot the distribution of the attribute.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with value counts and percentage distribution.\n",
    "    \"\"\"\n",
    "    if attribute not in dataframe.columns:\n",
    "        raise ValueError(f\"Attribute '{attribute}' not found in the dataset.\")\n",
    "\n",
    "    # Calculate value counts and percentage\n",
    "    counts = dataframe[attribute].value_counts()\n",
    "    percentages = (counts / counts.sum()) * 100\n",
    "\n",
    "    # Combine counts and percentages into a DataFrame\n",
    "    distribution = pd.DataFrame(\n",
    "        {\n",
    "            \"Value\": counts.index.astype(\n",
    "                str\n",
    "            ),  # Ensure all values are strings for categorical plotting\n",
    "            \"Frequency\": counts.values,\n",
    "            \"Percentage\": percentages.values,\n",
    "        }\n",
    "    ).set_index(\"Value\")\n",
    "\n",
    "    if not plot_distribution:\n",
    "        return distribution\n",
    "\n",
    "    fig = px.bar(\n",
    "        distribution.reset_index(),\n",
    "        x=\"Value\",\n",
    "        y=\"Percentage\",\n",
    "        text=\"Percentage\",\n",
    "        title=f\"Distribution of {attribute} (Percentage)\",\n",
    "        labels={\"Value\": \"Attribute Value\", \"Percentage\": \"Percentage (%)\"},\n",
    "    )\n",
    "    fig.update_traces(texttemplate=\"%{text:.2f}%\", textposition=\"outside\")\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(title=\"Values\"),\n",
    "        yaxis=dict(title=\"Percentage (%)\"),\n",
    "        uniformtext_minsize=8,\n",
    "        uniformtext_mode=\"hide\",\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single attribute\n",
    "attribute_distribution(df, \"size\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # All attributes\n",
    "# for column_name in df.columns:\n",
    "#     print(attribute_distribution(df, column_name, False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Try to describe the data set in just a few sentences. How is the data provided? Which kind of attributes are contained in the data set? How large is the data set in terms of the number of those elements (teams, matches, players, historic data, extra records, and so on)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OSHA Injury Tracking Application (ITA) dataset is a structured repository of work-related injury and illness records reported by establishments with 100 or more employees in high-hazard industries. The data is provided as a CSV file and contains attributes related to establishments (e.g., name, location, industry), incidents (e.g., date, type, outcome, days away from work), and employee roles (e.g., job title, Standard Occupation Codes). Additional narrative fields describe incidents and injuries in detail. The dataset size depends on the reporting frequency but typically includes thousands of records, each representing a unique incident, with detailed fields linking establishments, incidents, and employees for comprehensive analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (f) Analyze the errors and missing values. Write a function to count how many missing values per attribute and per entry you have. Analyze what are the most relevant missing values that might hinder the analysis according to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_and_plot_missing_values(dataframe):\n",
    "    \"\"\"\n",
    "    Analyzes and plots the missing values in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "        dataframe (pd.DataFrame): The DataFrame containing the dataset.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with:\n",
    "              - Total missing values per attribute\n",
    "              - Percentage of missing values per attribute\n",
    "              - Missing values per entry\n",
    "    \"\"\"\n",
    "    # Count missing values per attribute\n",
    "    missing_per_attribute = dataframe.isnull().sum()\n",
    "    percent_missing_per_attribute = (missing_per_attribute / len(dataframe)) * 100\n",
    "\n",
    "    # Combine counts and percentages into a DataFrame\n",
    "    attribute_analysis = (\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"Attribute\": dataframe.columns,\n",
    "                \"Missing_Count\": missing_per_attribute,\n",
    "                \"Percentage_Missing\": percent_missing_per_attribute,\n",
    "            }\n",
    "        )\n",
    "        .query(\"Missing_Count > 0\")\n",
    "        .sort_values(by=\"Percentage_Missing\", ascending=False)\n",
    "        .set_index(\"Attribute\")\n",
    "    )  # Sort in descending order\n",
    "\n",
    "    # Count missing values per entry (row)\n",
    "    missing_per_entry = dataframe.isnull().sum(axis=1)\n",
    "    # Distribution of rows by the number of missing values\n",
    "    row_missing_distribution = missing_per_entry.value_counts().reset_index()\n",
    "    row_missing_distribution.columns = [\"Missing_Count\", \"Row_Count\"]\n",
    "    row_missing_distribution = row_missing_distribution.sort_values(\n",
    "        by=\"Missing_Count\", ascending=True\n",
    "    ).set_index(\"Missing_Count\")\n",
    "\n",
    "    # Plot missing values per attribute\n",
    "    fig_attr = px.bar(\n",
    "        attribute_analysis.reset_index(),\n",
    "        x=\"Attribute\",\n",
    "        y=\"Percentage_Missing\",\n",
    "        text=\"Percentage_Missing\",\n",
    "        title=\"Missing Values Per Attribute (Sorted by Percentage)\",\n",
    "        labels={\n",
    "            \"Attribute\": \"Attribute\",\n",
    "            \"Percentage Missing\": \"Percentage Missing (%)\",\n",
    "        },\n",
    "    )\n",
    "    fig_attr.update_traces(texttemplate=\"%{text:.2f}%\", textposition=\"outside\")\n",
    "    fig_attr.update_layout(\n",
    "        xaxis=dict(title=\"Attributes\", tickangle=45),\n",
    "        yaxis=dict(title=\"Percentage Missing (%)\"),\n",
    "        uniformtext_minsize=8,\n",
    "        uniformtext_mode=\"hide\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "    fig_attr.show()\n",
    "\n",
    "    # Plot distribution of missing values per row\n",
    "    fig_row = px.bar(\n",
    "        row_missing_distribution.reset_index(),\n",
    "        x=\"Missing_Count\",\n",
    "        y=\"Row_Count\",\n",
    "        text=\"Row_Count\",\n",
    "        title=\"Distribution of Missing Values Per Row\",\n",
    "        labels={\n",
    "            \"Missing_Count\": \"Number of Missing Values\",\n",
    "            \"Row_Count\": \"Number of Rows\",\n",
    "        },\n",
    "    )\n",
    "    fig_row.update_traces(texttemplate=\"%{text}\", textposition=\"outside\")\n",
    "    fig_row.update_layout(\n",
    "        xaxis=dict(title=\"Number of Missing Values\"),\n",
    "        yaxis=dict(title=\"Number of Rows\"),\n",
    "        uniformtext_minsize=8,\n",
    "        uniformtext_mode=\"hide\",\n",
    "        showlegend=False,\n",
    "    )\n",
    "    fig_row.show()\n",
    "\n",
    "    return attribute_analysis, row_missing_distribution\n",
    "\n",
    "\n",
    "# Example usage\n",
    "df_missing_attributes, df_row_missing_distribution = analyze_and_plot_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_row_missing_distribution.query(\"Missing_Count > 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis\n",
    "1. **`date_of_death` (99.97% missing)**\n",
    "- **Impact**: This field is crucial for analyzing fatalities but is practically unusable due to the high missing percentage.\n",
    "- **Recommendation**: Use the `incident_outcome` field, which includes death as a category, to indirectly analyze fatality-related trends.\n",
    "\n",
    "2. **`time_started_work` (12.58% missing) and `time_of_incident` (12.48% missing)**\n",
    "- **Impact**: These fields are essential for analyzing temporal trends, such as incidents occurring shortly after starting work. Missing values reduce the reliability of time-dependent analyses.\n",
    "- **Recommendation**: Focus analyses on the available data or consider imputing missing values based on similar cases or statistical methods.\n",
    "\n",
    "3. **`ein` (8.60% missing)**\n",
    "- **Impact**: The EIN uniquely identifies establishments and is vital for merging datasets or conducting establishment-specific studies. Missing values hinder these analyses.\n",
    "- **Recommendation**: Use `establishment_ID` as an alternative identifier if it is complete.\n",
    "\n",
    "4. **`industry_description` (6.72% missing)**\n",
    "- **Impact**: Industry classification is critical for sector-specific risk analysis. Missing values hinder comparisons of workplace safety across industries.\n",
    "- **Recommendation**: Use `naics_code` for industry-level analysis or group missing values into an \"Unknown\" category.\n",
    "\n",
    "5. **`job_description` (0.41% missing)**\n",
    "- **Impact**: This field is important for analyzing risks associated with specific job roles. Missing data limits occupation-specific insights.\n",
    "- **Recommendation**: Exclude rows with missing `job_description` from job-specific analyses or impute values based on similar cases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 – Goal - Data (Domain specific)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General Overall Goal\n",
    "The primary goal of the visualization tool is to **enable workplace safety analysts, policymakers, and industry leaders** to:\n",
    "1. Identify trends in workplace injuries and illnesses across industries, establishments, and job roles.\n",
    "2. Explore the temporal, geographic, and sector-specific distribution of incidents to identify patterns and potential risk factors.\n",
    "3. Facilitate decision-making by highlighting areas that require safety interventions, such as industries with high incident rates or recurring issues in specific job roles.\n",
    "\n",
    "#### Target Users\n",
    "The visualization tool is designed for:\n",
    "- **Workplace Safety Analysts**: To understand patterns in workplace incidents and investigate contributing factors.\n",
    "- **Policymakers**: To design and evaluate regulations that mitigate risks in high-hazard industries.\n",
    "- **Industry Leaders/Managers**: To assess their establishments’ performance compared to industry benchmarks and implement targeted safety measures.\n",
    "\n",
    "#### Overall Goal and High-Level Actions\n",
    "The primary goal is **\"Exploratory Analysis\"**, focusing on:\n",
    "1. **Comparative Analysis**: Compare incidents across industries, job roles, and geographic regions to identify high-risk categories.\n",
    "2. **Trend Identification**: Examine temporal trends in incident occurrences and severity (e.g., time of day, seasonality).\n",
    "3. **Insight Generation**: Drill down into specific establishments or job types to identify recurring patterns or anomalies.\n",
    "4. **Communication and Awareness**: Present findings in an intuitive, interactive format to raise awareness and drive action.\n",
    "\n",
    "#### Why This Goal is Suitable for the Available Data\n",
    "- The dataset contains a wealth of detailed information about workplace incidents, including establishment-level, incident-level, and job-level attributes. These can be visualized to uncover patterns and correlations that would be hard to identify otherwise.\n",
    "- While some attributes have missing values (e.g., `date_of_death`, `time_started_work`), the remaining data is sufficient to provide meaningful insights at industry, establishment, and incident levels.\n",
    "\n",
    "#### Why Visualization is the Right Means\n",
    "1. **Pattern Recognition**: Visualization allows users to recognize patterns and outliers, such as industries with unusually high incident rates.\n",
    "2. **Exploration and Interaction**: An interactive tool enables users to explore the dataset from various perspectives (e.g., filtering by industry, geographic location, or incident severity).\n",
    "3. **Decision Support**: Visualizing data enables managers and policymakers to make informed decisions quickly by presenting complex data in an understandable format.\n",
    "4. **Communication**: Visualizations can convey insights effectively to diverse stakeholders, including non-technical audiences.\n",
    "\n",
    "This tool is ideal for leveraging the available data to inform workplace safety improvements, reduce incident rates, and ensure compliance with regulations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 – Data (What) Domain specific\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Write in section What (Data) the description of the data. You can base it on the analysis you have done in exercise 1. What are the general properties of the data you want to use? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Attributes Needed for the Analysis and Their Relevance\n",
    "\n",
    "1. **Establishment-Level Attributes**:\n",
    "   - **`naics_code` and `industry_description`**: Essential for identifying high-risk industries and understanding sector-specific trends.\n",
    "   - **`state`, `city`, `zip_code`**: Crucial for geographic analysis to detect regional patterns or disparities in workplace safety.\n",
    "   - **`size`, `annual_average_employees`, and `total_hours_worked`**: Provide context for scaling incident data (e.g., incidents per employee or hours worked) to make comparisons meaningful across establishments of different sizes.\n",
    "\n",
    "2. **Incident-Level Attributes**:\n",
    "   - **`date_of_incident`**: Key for temporal analysis, such as identifying trends over time or seasonal variations.\n",
    "   - **`type_of_incident`**: Important for categorizing and understanding the nature of incidents (e.g., injuries vs. illnesses).\n",
    "   - **`incident_outcome`**: Crucial for evaluating the severity of incidents and prioritizing interventions.\n",
    "   - **`dawf_num_away` and `djtr_num_tr`**: Provide metrics to assess the impact of incidents on productivity and employee health.\n",
    "\n",
    "3. **Narrative and Job-Level Attributes**:\n",
    "   - **`job_description`**: Helps identify which roles are most vulnerable to workplace incidents, enabling targeted interventions.\n",
    "   - **`SOC_code` and `SOC_description`**: Provide standard classifications for jobs, supporting cross-industry comparisons.\n",
    "   - **`incident_description` and `nar_what_happened`**: Offer qualitative insights into incident causes and circumstances, which are valuable for designing preventative measures.\n",
    "\n",
    "4. **System Metadata**:\n",
    "   - **`year_of_filing`**: Allows analysis of data trends across multiple reporting years.\n",
    "   - **`created_timestamp`**: Ensures timeliness and relevance of the data used for analysis.\n",
    "\n",
    "#### Why These Attributes Are Relevant\n",
    "These attributes enable comprehensive analyses aligned with the goals of the visualization tool:\n",
    "- **Comparative Analysis**: Attributes like `naics_code`, `state`, and `incident_outcome` allow comparisons across industries, regions, and severity levels.\n",
    "- **Trend Identification**: Temporal attributes such as `date_of_incident` and `year_of_filing` help identify trends in workplace safety over time.\n",
    "- **Actionable Insights**: Narrative and job-level attributes (`job_description`, `SOC_code`, and `incident_description`) provide detailed insights into specific incident causes, enabling targeted interventions.\n",
    "- **Scalability**: Workforce metrics (`size`, `annual_average_employees`, `total_hours_worked`) ensure that analyses are normalized, allowing for meaningful comparisons across establishments of varying sizes.\n",
    "\n",
    "By focusing on these attributes, the visualization tool can deliver actionable insights to workplace safety analysts, policymakers, and industry leaders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Most of the data sets contain noise, missing data values, and relations, or measurement errors. The data of this course is no exception. In exercise 1, you already looked at the missing values. How will you handle missing data values or measurement errors? Think of multiple ways and their pros and cons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocesses the given DataFrame by performing data cleaning, type conversions,\n",
    "    and mapping of categorical variables for better interpretability and analysis.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame containing raw data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A cleaned and preprocessed DataFrame with the following transformations:\n",
    "            - String columns are stripped of whitespace, tabs, and excess spaces.\n",
    "            - Numeric columns are converted to appropriate numeric types with downcasting.\n",
    "            - Categorical columns are mapped to meaningful labels and converted to 'category' type.\n",
    "            - Date and time columns are converted to datetime or time objects as needed.\n",
    "            - Missing values are imputed based on column-specific logic or filled with default placeholders.\n",
    "            - Invalid or placeholder values in specific columns (e.g., EIN, soc_code) are replaced with standardized values.\n",
    "            - Columns with redundant or irrelevant information (e.g., 'year_filing_for') are dropped.\n",
    "\n",
    "    Key Transformations:\n",
    "        - String Cleaning: Strips leading/trailing whitespace, removes tabs, and normalizes spacing.\n",
    "        - Numeric Conversion: Downcasts numeric columns to optimize memory usage.\n",
    "        - Categorical Mapping: Maps numeric or placeholder codes to meaningful labels.\n",
    "        - Date/Time Conversion: Parses date and time strings into appropriate formats.\n",
    "        - Missing Value Imputation:\n",
    "            - 'case_number', 'company_name', 'street_address', 'job_description': Filled with \"Not provided\".\n",
    "            - 'industry_description': Filled with \"No description given\".\n",
    "            - 'ein': \"Enter EIN\" replaced with \"No EIN Given\".\n",
    "            - 'time_unknown': Mapped to \"No\" by default if missing.\n",
    "            - Others: Column-specific imputation logic applied.\n",
    "        - Dropped Columns: 'year_filing_for'.\n",
    "\n",
    "    Notes:\n",
    "        - Assumes specific formats for date and time columns.\n",
    "        - Handles invalid or missing data gracefully using pandas' built-in capabilities (e.g., `errors='coerce'`).\n",
    "    \"\"\"\n",
    "\n",
    "    codes_to_drop = ['36-83962', '74-187392']\n",
    "    df_copy = df[~df['ein'].isin(codes_to_drop)].copy()\n",
    "    df_copy[\"ein\"] = (\n",
    "        df_copy[\"ein\"].str.replace(\"Enter EIN\", \"-1\").fillna(\"-1\")\n",
    "    )\n",
    "    # Define mappings and preprocessing rules\n",
    "    to_string = [\n",
    "        \"establishment_id\",\n",
    "        \"company_name\",\n",
    "        \"street_address\",\n",
    "        \"city\",\n",
    "        \"zip_code\",\n",
    "        \"industry_description\",\n",
    "        \"case_number\",\n",
    "        \"job_description\",\n",
    "        \"soc_code\",\n",
    "        \"soc_description\",\n",
    "        \"establishment_name\",\n",
    "        \"naics_code\",\n",
    "    ]\n",
    "    to_numeric = [\n",
    "        \"annual_average_employees\",\n",
    "        \"total_hours_worked\",\n",
    "        \"dafw_num_away\",\n",
    "        \"djtr_num_tr\",\n",
    "        \"ein\",\n",
    "    ]\n",
    "    categorical_mappings = {\n",
    "        \"establishment_type\": {\n",
    "            0.0: \"Invalid entry\",\n",
    "            1.0: \"Private industry\",\n",
    "            2.0: \"State government entity\",\n",
    "            3.0: \"Local government entity\",\n",
    "        },\n",
    "        \"size\": {1: \"<20\", 2: \"20-249\", 21: \"20-99\", 22: \"100-249\", 3: \"250+\"},\n",
    "        \"incident_outcome\": {\n",
    "            1: \"Death\",\n",
    "            2: \"Days away from work (DAFW)\",\n",
    "            3: \"Job transfer or restriction\",\n",
    "            4: \"Other recordable case\",\n",
    "        },\n",
    "        \"type_of_incident\": {\n",
    "            1: \"Injury\",\n",
    "            2: \"Skin disorder\",\n",
    "            3: \"Respiratory condition\",\n",
    "            4: \"Poisoning\",\n",
    "            5: \"Hearing Loss\",\n",
    "            6: \"All other illness\",\n",
    "        },\n",
    "        \"time_unknown\": {0: \"No\", 1: \"Yes\"},\n",
    "        \"soc_reviewed\": {0: \"Not reviewed\", 1: \"Reviewed\", 2: \"Not SOC coded\"},\n",
    "        \"state\": {\n",
    "            \"PA\": \"Pennsylvania\",\n",
    "            \"GA\": \"Georgia\",\n",
    "            \"VA\": \"Virginia\",\n",
    "            \"TX\": \"Texas\",\n",
    "            \"UT\": \"Utah\",\n",
    "            \"AZ\": \"Arizona\",\n",
    "            \"IN\": \"Indiana\",\n",
    "            \"TN\": \"Tennessee\",\n",
    "            \"WI\": \"Wisconsin\",\n",
    "            \"NC\": \"North Carolina\",\n",
    "            \"NY\": \"New York\",\n",
    "            \"OH\": \"Ohio\",\n",
    "            \"IA\": \"Iowa\",\n",
    "            \"AK\": \"Alaska\",\n",
    "            \"OK\": \"Oklahoma\",\n",
    "            \"MN\": \"Minnesota\",\n",
    "            \"MO\": \"Missouri\",\n",
    "            \"IL\": \"Illinois\",\n",
    "            \"CT\": \"Connecticut\",\n",
    "            \"NE\": \"Nebraska\",\n",
    "            \"LA\": \"Louisiana\",\n",
    "            \"WV\": \"West Virginia\",\n",
    "            \"NM\": \"New Mexico\",\n",
    "            \"CO\": \"Colorado\",\n",
    "            \"FL\": \"Florida\",\n",
    "            \"CA\": \"California\",\n",
    "            \"MD\": \"Maryland\",\n",
    "            \"AL\": \"Alabama\",\n",
    "            \"KY\": \"Kentucky\",\n",
    "            \"MI\": \"Michigan\",\n",
    "            \"SC\": \"South Carolina\",\n",
    "            \"ID\": \"Idaho\",\n",
    "            \"KS\": \"Kansas\",\n",
    "            \"MS\": \"Mississippi\",\n",
    "            \"AR\": \"Arkansas\",\n",
    "            \"NV\": \"Nevada\",\n",
    "            \"NH\": \"New Hampshire\",\n",
    "            \"VT\": \"Vermont\",\n",
    "            \"NJ\": \"New Jersey\",\n",
    "            \"DE\": \"Delaware\",\n",
    "            \"MA\": \"Massachusetts\",\n",
    "            \"ND\": \"North Dakota\",\n",
    "            \"WA\": \"Washington\",\n",
    "            \"OR\": \"Oregon\",\n",
    "            \"ME\": \"Maine\",\n",
    "            \"SD\": \"South Dakota\",\n",
    "            \"MT\": \"Montana\",\n",
    "            \"PR\": \"Puerto Rico\",\n",
    "            \"RI\": \"Rhode Island\",\n",
    "            \"WY\": \"Wyoming\",\n",
    "            \"HI\": \"Hawaii\",\n",
    "            \"DC\": \"District of Columbia\",\n",
    "            \"VI\": \"U.S. Virgin Islands\",\n",
    "            \"GU\": \"Guam\",\n",
    "            \"MP\": \"Northern Mariana Islands\",\n",
    "            \"AS\": \"American Samoa\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Convert to string and clean text\n",
    "    df_copy[to_string] = (\n",
    "        df_copy[to_string]\n",
    "        .astype(\"string\")\n",
    "        .apply(\n",
    "            lambda col: col.str.strip()\n",
    "            .str.replace(r\"\\t\", \"\", regex=True)\n",
    "            .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Convert to numeric with downcasting\n",
    "    df_copy[to_numeric] = df_copy[to_numeric].apply(\n",
    "        pd.to_numeric, errors=\"coerce\", downcast=\"integer\"\n",
    "    )\n",
    "    df_copy[\"soc_probability\"] = df_copy[\"soc_probability\"].apply(\n",
    "        pd.to_numeric, errors=\"coerce\", downcast=\"float\"\n",
    "    )\n",
    "\n",
    "    # Map categorical columns\n",
    "    for col, mapping in categorical_mappings.items():\n",
    "        if col in df_copy:\n",
    "            df_copy[col] = (\n",
    "                df_copy[col].map(mapping).fillna(\"Not stated\").astype(\"category\")\n",
    "            )\n",
    "\n",
    "    # Handle specific columns\n",
    "    df_copy[\"case_number\"] = df_copy[\"case_number\"].fillna(\"Not provided\")\n",
    "    df_copy[\"company_name\"] = df_copy[\"company_name\"].fillna(\"Not provided\")\n",
    "    df_copy[\"street_address\"] = df_copy[\"street_address\"].fillna(\"\")\n",
    "    df_copy[\"naics_year\"] = (\n",
    "        df_copy[\"naics_year\"].fillna(\"Invalid NAICS codes\").astype(\"category\")\n",
    "    )\n",
    "    df_copy[\"industry_description\"] = df_copy[\"industry_description\"].fillna(\n",
    "        \"No description given\"\n",
    "    )\n",
    "    df_copy[\"job_description\"] = df_copy[\"job_description\"].fillna(\"No job description\")\n",
    "    df_copy[\"soc_code\"] = (\n",
    "        df_copy[\"soc_code\"].replace(\"0000\", \"00-0000\").replace(\"9999\", \"99-9999\")\n",
    "    )\n",
    "\n",
    "    # Date and time conversions\n",
    "    date_columns = {\n",
    "        \"date_of_incident\": \"%m/%d/%Y\",\n",
    "        \"date_of_death\": \"%m/%d/%Y\",\n",
    "        \"created_timestamp\": \"%d%b%y:%H:%M:%S\",\n",
    "    }\n",
    "    for col, fmt in date_columns.items():\n",
    "        df_copy[col] = pd.to_datetime(df_copy[col], format=fmt, errors=\"coerce\")\n",
    "\n",
    "\n",
    "    time_columns = [\"time_started_work\", \"time_of_incident\"]\n",
    "\n",
    "    for col in time_columns:\n",
    "        # Convert to datetime\n",
    "        df_copy[col] = pd.to_datetime(df_copy[col], format=\"%H:%M:%S.%f\", errors=\"coerce\")\n",
    "        # TODO: potentially duplicated data, but decided to leave both\n",
    "        # Add hours and minutes columns\n",
    "        df_copy[f\"{col}_hours\"] = df_copy[col].dt.hour\n",
    "        df_copy[f\"{col}_minutes\"] = df_copy[col].dt.minute\n",
    "\n",
    "    # Since it's just 2023, and it does not provide any info\n",
    "    df_copy = df_copy.drop(columns=\"year_filing_for\")\n",
    "    # Outlier values are contained by default [172307584.0, 126.0]\n",
    "    # and [307584.0, 273751.0]. The number of employees is taken from\n",
    "    # https://www.zippia.com/golden-state-foods-careers-24869/demographics/\n",
    "    # and then hours are imputed for roughly same scale companies\n",
    "    # df_copy.loc[\n",
    "    #     df[\"company_name\"] == \"Golden State Foods\",\n",
    "    #     [\"annual_average_employees\", \"total_hours_worked\"],\n",
    "    # ] = [\n",
    "    #     4000,\n",
    "    #     df_copy.query(\"3000 < annual_average_employees < 5000\")[\n",
    "    #         \"total_hours_worked\"\n",
    "    #     ].median(),\n",
    "    # ]\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "df_preproc = preprocess_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"street_address\"].sample(50)\n",
    "# TODO: using the soc_code classifier find all the soc_descriptions\n",
    "df[[\"soc_code\", \"soc_description\"]].sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc.query(\"soc_probability != 5 & soc_reviewed == 'Reviewed'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory = \"datasets\"\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "df.to_parquet(os.path.join(output_directory, \"processed_data.parquet\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) (Data (What)) Choose one of the methods and implement it for the data set. Describe it in the section and mention what is the effect on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df_preproc.select_dtypes(include=[np.number])\n",
    "\n",
    "for column in df_numeric.columns:\n",
    "    fig_incident = px.histogram(\n",
    "        df_numeric, x=column, title=f\"Histogram of {column}\", nbins=50, text_auto=True\n",
    "    )\n",
    "    fig_incident.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = df_preproc[df_preproc.select_dtypes(include=[\"datetime\"]).columns]\n",
    "\n",
    "for column in df_time.columns:\n",
    "    fig_incident = px.histogram(\n",
    "        df_time[df_time[column].notna()],\n",
    "        x=column,\n",
    "        title=f\"Histogram of {column}\",\n",
    "        nbins=100,\n",
    "    )\n",
    "    fig_incident.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical = df_preproc.select_dtypes(include=[\"category\"])\n",
    "\n",
    "# Generate histograms for categorical data\n",
    "for column in df_categorical.columns:\n",
    "    fig = px.histogram(\n",
    "        df_categorical[column].dropna(),\n",
    "        x=column,\n",
    "        title=f\"Distribution of {column}\",\n",
    "        text_auto=True,\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El problemo: wtf is happening to company employees and hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df_preproc.query(\"annual_average_employees > 3_500_000\")[[\"annual_average_employees\", \"total_hours_worked\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc.query(\"total_hours_worked > 2000000000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df = df_preproc.copy()\n",
    "ratio_df[\"hours_employee_ratio\"] = (\n",
    "    ratio_df[\"total_hours_worked\"] / ratio_df[\"annual_average_employees\"]\n",
    ")\n",
    "ratio_df.query(\"hours_employee_ratio < 1 | hours_employee_ratio > 4000\").sort_values(\n",
    "    \"hours_employee_ratio\"\n",
    ").groupby(\"company_name\")[\"establishment_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_and_plot_missing_values(df_preproc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 – Data (What) Abstraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| id | Variable Name               | Description                                                                                                                                                                        | Data Type         |\n",
    "|----|-----------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------|\n",
    "| 1  | establishment_id           | Identifier for the establishment.                                                                                                                                                  | string            |\n",
    "| 2  | establishment_name         | The name of the establishment reporting data.                                                                                                                                       | string            |\n",
    "| 3  | ein                        | Employer Identification Number (EIN) is also known as Federal Tax Identification Number. Has 9 digit format. If not given, states “No EIN Given”.                                   | float64            |\n",
    "| 4  | company_name               | The name of the company that owns the establishment.                                                                                                                               | string            |\n",
    "| 5  | street_address             | The street address of the establishment. If not given, states “Not provided”.                                                                                                      | string            |\n",
    "| 6  | city                       | The city where the establishment is located.                                                                                                                                       | string            |\n",
    "| 7  | state                      | Full name of the state or territory where the establishment is located.                                                                                                            | category          |\n",
    "| 8  | zip_code                   | The full zip code for the establishment. Can be converted to numbers, but stored as a string for interpretability.                                                                 | string            |\n",
    "| 9  | naics_code                 | The North American Industry Classification System (NAICS) code for the establishment. Data use a 2012, 2017, or 2022 NAICS code.                                                  | string            |\n",
    "| 10 | naics_year                 | The calendar year reflecting the version of NAICS codes used by the establishment [2012, 2017, or 2022]. Invalid NAICS codes are shown as “Invalid NAICS codes”.                   | category          |\n",
    "| 11 | industry_description       | The industry description for the establishment.                                                                                                                                    | string            |\n",
    "| 12 | establishment_type         | Type of establishment: Private industry, State government entity, Local government entity.                                                                                         | category          |\n",
    "| 13 | size                       | The size of the establishment is employer-reported and based on the maximum number of employees who worked there at any point in the year: <20, 20-249, 20-99, 100-249, 250+.      | category          |\n",
    "| 14 | annual_average_employees   | The annual average number of employees at the establishment. Note: This field should not be summed across cases in an establishment.                                               | int32             |\n",
    "| 15 | total_hours_worked         | The total hours worked by all employees at the establishment. Note: This field should not be summed across cases in an establishment.                                              | int64             |\n",
    "| 16 | case_number                | An employer-assigned case number for each unique case (i.e., injured/ill employee).                                                                                                | string            |\n",
    "| 17 | job_description            | The job title of the injured/ill employee.                                                                                                                                          | string            |\n",
    "| 18 | soc_code                   | The 2018 Standard Occupation Code (SOC) assigned by the NIOSH Industry and Occupation Computerized Coding System (NIOCCS) or OSHA.                                                  | string            |\n",
    "| 19 | soc_description            | Text description of the 2018 SOC Code.                                                                                                                                              | string            |\n",
    "| 20 | soc_reviewed               | Indicator variable as to whether the SOC code was manually reviewed before posting: Not reviewed, Reviewed, Not SOC coded.                                                         | category          |\n",
    "| 21 | soc_probability            | The score given by the NIOSH Industry and Occupation Computerized Coding System (NIOCCS) for the expected accuracy of the SOC code. Codes assigned directly by OSHA are given a score of 5. | float64           |\n",
    "| 22 | date_of_incident           | The date the incident occurred.                                                                                                                                                    | datetime64[ns]    |\n",
    "| 23 | incident_outcome           | The most serious outcome that occurred: Death, Days away from work (DAFW), Job transfer or restriction, Other recordable case.                                                     | category          |\n",
    "| 24 | dafw_num_away              | The number of days away from work the employee required to recover from the incident before returning to work.                                                                      | int16             |\n",
    "| 25 | djtr_num_tr                | The number of days the employee needed to be transferred or reassigned to another job or placed on restricted duty due to the incident.                                             | int16             |\n",
    "| 26 | type_of_incident           | The type of incident that occurred: Injury, Skin disorder, Respiratory condition, Poisoning, Hearing Loss, All other illness.                                                      | category          |\n",
    "| 27 | time_started_work          | The time the affected employee started work prior to the incident.                                                                                                                 | datetime64[ns]    |\n",
    "| 28 | time_of_incident           | The time the incident occurred. Can have none values.                                                                                                                                                   | datetime64[ns]    |\n",
    "| 29 | time_unknown               | Was the time of the incident unknown? Yes, No.                                                                                                                                      | category          |\n",
    "| 30 | date_of_death              | The date the death occurred, if applicable. Can have none values.                                                                                                                                       | datetime64[ns]    |\n",
    "| 31 | created_timestamp          | Timestamp when the record was created. Can have none values.                                                                                                                                             | datetime64[ns]    |\n",
    "| 32 | time_started_work_minutes  | The minute component of the time the affected employee started work prior to the incident. Can have missing values.                           | float64           |\n",
    "| 33 | time_of_incident_hours     | The hour component of the time the incident occurred. Can have missing values.                                                                | float64           |\n",
    "| 34 | time_of_incident_minutes   | The minute component of the time the incident occurred. Can have missing values.                                                              | float64           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
